- name: Create prometheus rules for alerts
  kubernetes.core.k8s:
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: PrometheusRule
      metadata:
        name: "{{ app.name }}-alerts"
        namespace: "{{ openshift_namespace }}"
        labels:
          app: "{{ app.name }}"
      spec:
        groups:
          - name: "{{ app.name }}-sync-alerts"
            rules:
              - alert: "{{ app.display_name }}SyncJobFailed"
                expr: >
                  kube_job_failed{namespace="{{ openshift_namespace }}", job_name="{{ app.name }}-sync"} > 0
                for: 5m
                labels:
                  severity: critical
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} sync job failed"
                  description: >-
                    The {{ app.display_name }} sync job has failed. Check logs for details.

              - alert: "{{ app.display_name }}SyncJobDidNotRun"
                expr: >
                  (hour() > 5 or hour() < 2) and
                  (time() - max(kube_job_status_start_time{namespace="{{ openshift_namespace }}", job_name=~"{{ app.name }}-sync.*"})) > 24 * 3600
                for: 5m
                labels:
                  severity: warning
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} sync didn't run in scheduled window"
                  description: >-
                    The {{ app.display_name }} sync job didn't execute during its scheduled window (2h - 5h UTC).

              - alert: "{{ app.display_name }}SyncJobRunningTooLong"
                expr: >
                  time() - kube_job_status_start_time{namespace="{{ openshift_namespace }}", job_name="{{ app.name }}-sync"} > 3600
                for: 5m
                labels:
                  severity: critical
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} sync running too long"
                  description: >-
                    The {{ app.display_name }} sync job has been running for more than 1 hour.

          - name: "{{ app.name }}-pod-alerts"
            rules:
              - alert: "{{ app.display_name }}PodRestartingTooOften"
                expr: >
                  increase(kube_pod_container_status_restarts_total{namespace="{{ openshift_namespace }}", pod=~"{{ app.name }}-.*", pod!~"{{ app.name }}-(sync|redis|exporter).*"}[30m]) > 3
                for: 5m
                labels:
                  severity: critical
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} application pod restarting too often"
                  description: >-
                    The {{ app.display_name }} application pod has restarted more than 3 times in the last 30 minutes.

              - alert: "{{ app.display_name }}PodMissing"
                expr: >
                  absent(kube_pod_info{namespace="{{ openshift_namespace }}", pod=~"{{ app.name }}-[^(sync|redis|exporter)].*"}) == 1
                for: 15s
                labels:
                  severity: critical
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} application pod is missing"
                  description: >-
                    No {{ app.display_name }} application pod is running for more than 15 seconds.

              - alert: "{{ app.display_name }}PodNotReady"
                expr: >
                  sum by (pod) (kube_pod_status_phase{namespace="{{ openshift_namespace }}", pod=~"{{ app.name }}-[^(sync|redis|exporter)].*", phase=~"Running|Pending"}) > 0
                  and
                  sum by (pod) (kube_pod_status_ready{namespace="{{ openshift_namespace }}", pod=~"{{ app.name }}-[^(sync|redis|exporter)].*", condition="true"}) == 0
                for: 45s
                labels:
                  severity: critical
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} application pod is not ready"
                  description: >-
                    The {{ app.display_name }} application pod is running but not ready for more than 45 seconds.

          - name: "{{ app.name }}-redis-alerts"
            rules:
              - alert: "{{ app.display_name }}RedisPodMissing"
                expr: >
                  absent(kube_pod_info{namespace="{{ openshift_namespace }}", pod=~"{{ app.name }}-redis-.*"})
                for: 15s
                labels:
                  severity: critical
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} Redis pod is missing"
                  description: >-
                    No Redis pod for {{ app.display_name }} is running for more than 15 seconds.

- name: Create outline exporter deployment
  kubernetes.core.k8s:
    definition:
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: "{{ app.name }}-exporter"
        namespace: "{{ openshift_namespace }}"
        labels:
          app: "{{ app.name }}"
          component: exporter
      spec:
        replicas: 1
        selector:
          matchLabels:
            app: "{{ app.name }}"
            component: exporter
        template:
          metadata:
            labels:
              app: "{{ app.name }}"
              component: exporter
            annotations:
              prometheus.io/scrape: "true"
              prometheus.io/port: "9877"
              prometheus.io/path: /metrics
          spec:
            containers:
              - name: exporter
                image: "{{ registry.url }}/{{ registry.organization }}/{{ app.name }}-exporter:{{ monitoring.exporter_version }}"
                imagePullPolicy: Always
                ports:
                  - containerPort: 9877
                    name: metrics
                env:
                  - name: OUTLINE_API_URL
                    value: "{{ app_url }}"
                  - name: OUTLINE_API_KEY
                    valueFrom:
                      secretKeyRef:
                        name: "{{ app.name }}-api-key-monitoring"
                        key: API_KEY
                resources:
                  requests:
                    cpu: "{{ current_resources.exporter.requests.cpu }}"
                    memory: "{{ current_resources.exporter.requests.memory }}"
                  limits:
                    memory: "{{ current_resources.exporter.limits.memory }}"
                readinessProbe:
                  httpGet:
                    path: /healthz
                    port: metrics
                    scheme: HTTP
                livenessProbe:
                  httpGet:
                    path: /healthz
                    port: metrics
                    scheme: HTTP
            imagePullSecrets:
              - name: "{{ pull_secret_name }}"

- name: Create pod monitor for exporter
  kubernetes.core.k8s:
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: PodMonitor
      metadata:
        name: "{{ app.name }}-exporter"
        namespace: "{{ openshift_namespace }}"
        labels:
          app: "{{ app.name }}"
          component: exporter
      spec:
        selector:
          matchLabels:
            app: "{{ app.name }}"
            component: exporter
        namespaceSelector:
          matchNames:
            - "{{ openshift_namespace }}"
        podMetricsEndpoints:
          - port: metrics
            interval: 1m
            path: /metrics

- name: Deploy HTTP endpoint probe
  kubernetes.core.k8s:
    definition:
      apiVersion: monitoring.rhobs/v1
      kind: Probe
      metadata:
        name: "{{ app.name }}-http-probe"
        namespace: "{{ openshift_namespace }}"
        labels:
          app: "{{ app.name }}"
      spec:
        interval: "{{ monitoring.probe_interval }}"
        scrapeTimeout: "{{ monitoring.probe_timeout }}"
        module: http_2xx
        prober:
          url: prometheus-blackbox-exporter.monitoring.svc.cluster.local:9115
        targets:
          staticConfig:
            static:
              - "{{ app_url }}"
        metricRelabelings:
          - sourceLabels: [__address__]
            targetLabel: instance
          - sourceLabels: [__address__]
            targetLabel: target
          - targetLabel: job
            replacement: "{{ app.name }}-probe"

- name: Create probe alerts
  kubernetes.core.k8s:
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: PrometheusRule
      metadata:
        name: "{{ app.name }}-probe-alerts"
        namespace: "{{ openshift_namespace }}"
        labels:
          app: "{{ app.name }}"
      spec:
        groups:
          - name: "{{ app.name }}-endpoint-alerts"
            rules:
              - alert: "{{ app.display_name }}EndpointDown"
                expr: >
                  probe_success{job="{{ app.name }}-probe"} == 0
                for: 1m
                labels:
                  severity: critical
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} endpoint is down"
                  description: >-
                    The {{ app.display_name }} endpoint {{ app_url }} has been unreachable for over 1 minute.

              - alert: "{{ app.display_name }}SlowResponse"
                expr: >
                  probe_duration_seconds{job="{{ app.name }}-probe"} > 2
                for: 5m
                labels:
                  severity: warning
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} slow response time"
                  description: >-
                    The {{ app.display_name }} endpoint is responding slowly (>2s) for over 5 minutes.

              - alert: "{{ app.display_name }}SSLCertExpiringSoon"
                expr: >
                  probe_ssl_earliest_cert_expiry{job="{{ app.name }}-probe"} - time() < 86400 * 14
                for: 1h
                labels:
                  severity: warning
                  sendto: telegram
                  app: "{{ app.name }}"
                annotations:
                  summary: "{{ app.display_name }} SSL certificate expiring soon"
                  description: >-
                    The SSL certificate for {{ app.display_name }} will expire in less than 14 days.
